{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"electra_fine_tune_explain_captum_ig.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f73e507aa2af47b3bc9cecd39821272f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb5e9861778a41bca2fdf67b1b0aca9f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_89c9e759616e4b1882c6d448bc874a47","IPY_MODEL_ee6ad952e46c425cacafd0e9c5613358"]}},"cb5e9861778a41bca2fdf67b1b0aca9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89c9e759616e4b1882c6d448bc874a47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a6c5133f196f46d5ad1655e18914d0fb","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9c2d45d97f64d92835a11ce052ecddb"}},"ee6ad952e46c425cacafd0e9c5613358":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_224b778ebbbd4f6380bf710cc4094091","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [19:17&lt;00:00, 385.90s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f135b4c180804c68a0d67672d43082b9"}},"a6c5133f196f46d5ad1655e18914d0fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9c2d45d97f64d92835a11ce052ecddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"224b778ebbbd4f6380bf710cc4094091":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f135b4c180804c68a0d67672d43082b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd727c3a5360428ba44fbf6d564d8df4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1ae766edb0084cdbb03df357e8f66027","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b75d7fd1e89e495a8459cdef9f027fed","IPY_MODEL_6b2c10864ae344908749bf8b1ad5a42a"]}},"1ae766edb0084cdbb03df357e8f66027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b75d7fd1e89e495a8459cdef9f027fed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_85bd960653d7498faca5a9e3bc74c2d3","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2104,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2104,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_425b95afa62f4638b3bed921805fd957"}},"6b2c10864ae344908749bf8b1ad5a42a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bcaf3f3d4c51403f8fe045a22cfd81b0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2104/2104 [06:25&lt;00:00,  5.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f67cc405c24840ea83f58383f7472cdf"}},"85bd960653d7498faca5a9e3bc74c2d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"425b95afa62f4638b3bed921805fd957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcaf3f3d4c51403f8fe045a22cfd81b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f67cc405c24840ea83f58383f7472cdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c59a3412feed434cac44176654149978":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe97b77788224e3b8af9520c2ac33add","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_54d822a702ba464c9cc609b618d51e6d","IPY_MODEL_c3731d79202245518597cda28ccf2c45"]}},"fe97b77788224e3b8af9520c2ac33add":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54d822a702ba464c9cc609b618d51e6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cbd92d1919bc41b0b68e34eaf47c091f","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_26867d3755a1442aa8feceb57e55fc27"}},"c3731d79202245518597cda28ccf2c45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a7287cb64bac4faab74683df6a099946","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [00:01&lt;00:00, 55.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e7f03852cca46aba8e2bd51bc96c7e9"}},"cbd92d1919bc41b0b68e34eaf47c091f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"26867d3755a1442aa8feceb57e55fc27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7287cb64bac4faab74683df6a099946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e7f03852cca46aba8e2bd51bc96c7e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46add80a07f648f285225de09e8b2a31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bdb5165a1e32420a9b86395ea9285fc3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8e5d9d6488ee462b9a4213c58847e2cd","IPY_MODEL_49333a9665414763bd677232a64eecd4"]}},"bdb5165a1e32420a9b86395ea9285fc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e5d9d6488ee462b9a4213c58847e2cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_75dbc827cef6468ea83a3f8e7a092293","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e038c9bde67b4e1b95b39afbf5e21e71"}},"49333a9665414763bd677232a64eecd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c664b8fa3df74148bd73637c64e3741d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [00:02&lt;00:00, 53.86it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4320efbb0f9e47599d8c02bdd9539211"}},"75dbc827cef6468ea83a3f8e7a092293":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e038c9bde67b4e1b95b39afbf5e21e71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c664b8fa3df74148bd73637c64e3741d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4320efbb0f9e47599d8c02bdd9539211":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"071ed4f183234e06b4c620916d6f971a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4251ab35d77740949abd90398d308ea6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_86dbe43a671e42a5a29cfb509d658502","IPY_MODEL_80bc136aae3848d48df1dcbe16a29c8b"]}},"4251ab35d77740949abd90398d308ea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86dbe43a671e42a5a29cfb509d658502":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a763ff9547144f97b6e9f9849db6e203","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2104,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2104,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f79b10f21abe4e54909f1c420b872c79"}},"80bc136aae3848d48df1dcbe16a29c8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d194a640dce499990393bc17972c969","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2104/2104 [06:25&lt;00:00,  5.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c9e3f61056c3409fbd28dbb592568f0e"}},"a763ff9547144f97b6e9f9849db6e203":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f79b10f21abe4e54909f1c420b872c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d194a640dce499990393bc17972c969":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c9e3f61056c3409fbd28dbb592568f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80ecb10f47f1468081c6cbd5ef54e3dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67521551b9ce43eaaebd943146572a6c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b8ecc557cd4f4d138e30cc054fb371fa","IPY_MODEL_de7ef6bd81384184999d699f5b0977fe"]}},"67521551b9ce43eaaebd943146572a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8ecc557cd4f4d138e30cc054fb371fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a5c9c95c96854b218b83e2d785100e2e","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8059bf371b3e4896ab437f2962c06c24"}},"de7ef6bd81384184999d699f5b0977fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6e6c455e8fba44d3900bafa6844a0ec3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [01:32&lt;00:00,  1.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23af2d5302f74442b9242beeaedb4e6e"}},"a5c9c95c96854b218b83e2d785100e2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8059bf371b3e4896ab437f2962c06c24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e6c455e8fba44d3900bafa6844a0ec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23af2d5302f74442b9242beeaedb4e6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9476a88f5c394674b5a79aa90d481598":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d89bdb4bd708498da09f02d11eee8620","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c7ebec1f8c264a2a9c809ce341849513","IPY_MODEL_a445bc39d3d9485381de6820357a753a"]}},"d89bdb4bd708498da09f02d11eee8620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7ebec1f8c264a2a9c809ce341849513":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8fb34007c6be41dca6c7eedd9dd1d1a8","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e469b003f5d548949472a9158a6b94e1"}},"a445bc39d3d9485381de6820357a753a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fdf7b79eab204aafacf9c0327df53d87","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [00:02&lt;00:00, 52.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7abb30db3f4b479d97fa9be23d864057"}},"8fb34007c6be41dca6c7eedd9dd1d1a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e469b003f5d548949472a9158a6b94e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fdf7b79eab204aafacf9c0327df53d87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7abb30db3f4b479d97fa9be23d864057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f0853b9c0af4d938cc2578b574f772d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d47b456926e49389efc1df760552a12","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4e9bcaab7300487190191dd657da8897","IPY_MODEL_513ad2b8d82f4087ae4cd00acd13efb6"]}},"7d47b456926e49389efc1df760552a12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e9bcaab7300487190191dd657da8897":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89630710c77e4b9f9bb0b548ebdd741b","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2104,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2104,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cbe638e211d94de699c9484f8b860e30"}},"513ad2b8d82f4087ae4cd00acd13efb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a60d9126cb05441b852b1b5e83ddedda","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2104/2104 [06:25&lt;00:00,  5.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06a3e7f0fa94452ea2a565effa6dd1d3"}},"89630710c77e4b9f9bb0b548ebdd741b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cbe638e211d94de699c9484f8b860e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a60d9126cb05441b852b1b5e83ddedda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"06a3e7f0fa94452ea2a565effa6dd1d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae2835670a1a4eb6b27879234e85bab2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ec925cd82cc417d99fe24912fb25d9b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_63aa766714c4413a8a5172153d837f8a","IPY_MODEL_4c3f89db878a43788725cd22a994efc8"]}},"8ec925cd82cc417d99fe24912fb25d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63aa766714c4413a8a5172153d837f8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_631b0da0249f40e7b3be1947b4745715","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9105d44d9a114e9bb5a6d2275a993530"}},"4c3f89db878a43788725cd22a994efc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cf2d35898b9a4945949c632c83b491ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [00:02&lt;00:00, 53.33it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a45f564fded244cf9e4cc502b2f2eeb7"}},"631b0da0249f40e7b3be1947b4745715":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9105d44d9a114e9bb5a6d2275a993530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf2d35898b9a4945949c632c83b491ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a45f564fded244cf9e4cc502b2f2eeb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"79e850e398b04d8a9891ebc7280a4942":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_91e449f7bde348a0b2a650ed86eee68d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d93a5d24dd3344cdb6f78960439fe2cb","IPY_MODEL_8aa7da438be64279997d835154e13a2d"]}},"91e449f7bde348a0b2a650ed86eee68d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d93a5d24dd3344cdb6f78960439fe2cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5fd9d67b3b2248148de23d91692ef665","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb351c57a6a74011854eafa5da7861eb"}},"8aa7da438be64279997d835154e13a2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_17ee77e84d9244329809f038eba816e7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [08:59&lt;00:00,  4.95s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_798cf207c5d84d0fb4ce75b1c7b64755"}},"5fd9d67b3b2248148de23d91692ef665":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eb351c57a6a74011854eafa5da7861eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17ee77e84d9244329809f038eba816e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"798cf207c5d84d0fb4ce75b1c7b64755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c714791ade614317a9bd7cb1e251735c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d399d03dc6504709a348ba34e7df9a4e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1b86f24b12bc4338a8f03775a90f8bec","IPY_MODEL_00c3629ee3014c0d837f856f36356a1e"]}},"d399d03dc6504709a348ba34e7df9a4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b86f24b12bc4338a8f03775a90f8bec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_17408ba9c3584cafbfd1cf5038532841","_dom_classes":[],"description":"Evaluation: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ae88ef38e5146018d500932aee7a195"}},"00c3629ee3014c0d837f856f36356a1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e1d5227d28e94010b357ba2adea13187","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [02:25&lt;00:00,  1.33s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b3734aada6547c0850a77e8df9bd32f"}},"17408ba9c3584cafbfd1cf5038532841":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0ae88ef38e5146018d500932aee7a195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e1d5227d28e94010b357ba2adea13187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9b3734aada6547c0850a77e8df9bd32f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56590e5eb66f49faa8422f3f4cddf185":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6afb1fd969014ce2a2e4604cec10f220","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_16d939947de14769bc993b5bb62840ed","IPY_MODEL_b374e540049c44f7998d2298032384b5"]}},"6afb1fd969014ce2a2e4604cec10f220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"16d939947de14769bc993b5bb62840ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fae44be6b2af4296992cf0a284683e5e","_dom_classes":[],"description":"Prediction: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de35220dcb8044768bdaf74c48c785d3"}},"b374e540049c44f7998d2298032384b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d8e3d612d15427188729f940d503d39","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109/109 [00:02&lt;00:00, 51.05it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0f46e709e74432581515986d9ce2c0e"}},"fae44be6b2af4296992cf0a284683e5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"de35220dcb8044768bdaf74c48c785d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d8e3d612d15427188729f940d503d39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0f46e709e74432581515986d9ce2c0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"6FD5B2B7Kq-V","colab_type":"text"},"source":["[GitHub](https://github.com/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_explain_captum_ig.ipynb)\n","# Content\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"di_oai-BvG5k","colab_type":"text"},"source":["\n","This notebook contains an example of [fine-tuning](https://huggingface.co/transformers/training.html) an [Electra](https://huggingface.co/transformers/model_doc/electra.html) model on the [GLUE SST-2](https://nlp.stanford.edu/sentiment/index.html) dataset. After fine-tuning, the [Integrated Gradients](https://arxiv.org/pdf/1703.01365.pdf) **interpretability** method is applied to compute tokens' attributions for each target class. \n","* We will instantiate a pre-trained Electra model from the [Transformers](https://huggingface.co/transformers/) library. \n","* The data is downloaded from the [nlp](https://huggingface.co/nlp/) library. The input text is tokenized with [ElectraTokenizerFast](https://huggingface.co/transformers/model_doc/electra.html#electratokenizerfast) tokenizer backed by HF [tokenizers](https://huggingface.co/transformers/main_classes/tokenizer.html) library.\n","* **Fine-tuning** for sentiment analysis is handled by the [Trainer](https://huggingface.co/transformers/main_classes/trainer.html) class. \n","* After fine-tuning, the [Integrated Gradients](https://captum.ai/api/integrated_gradients.html) interpretability algorithm will assign importance scores to\n","input tokens. We will use a **PyTorch** implementation from the [Captum](https://captum.ai/) library. \n","  - The algorithm requires providing a reference sample (a baseline) since importance attribution is performed based on the model's output, as inputs change from reference values to the actual sample. \n","  - The Integrated Gradients method satisfies the [completeness](http://theory.stanford.edu/~ataly/Talks/sri_attribution_talk_jun_2017.pdf) property. We will look at the sum of attributions for a sample and show that the sum approximates (explains) prediction's shift from the baseline value. \n","* The final sections of this notebook contain a colour-coded **visualization** of attribution results made with *captum.attr.visualization* library.\n","\n","The notebook is based on the [Hugging Face documentation](https://huggingface.co/) and the implementation of Integrated Gradients attribution methods is adapted from the Captum.ai\n","[Interpreting BERT Models (Part 1)](https://captum.ai/tutorials/Bert_SQUAD_Interpret)."]},{"cell_type":"markdown","metadata":{"id":"Qi5nKLqupSt_","colab_type":"text"},"source":["# Installation & imports\n","\n","---"]},{"cell_type":"code","metadata":{"id":"n23Rko2YVSLQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":945},"executionInfo":{"status":"ok","timestamp":1596628985961,"user_tz":-120,"elapsed":18675,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"7643150a-7390-4f93-d641-7924b4524a12"},"source":["!pip install transformers\n","# pyarrow version as required by nlp v. 0.3.0 (runtime restart in Colab)\n","!pip install \"pyarrow==0.16.0\"  \n","!pip install nlp\n","!pip install captum"],"execution_count":147,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyarrow==0.16.0 in /usr/local/lib/python3.6/dist-packages (0.16.0)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.18.5)\n","Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.15.0)\n","Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.5)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (0.16.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n","Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.16.0->nlp) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n","Requirement already satisfied: captum in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from captum) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from captum) (1.18.5)\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from captum) (1.6.0+cu101)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.8.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->captum) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->captum) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FctqAnsgVcQP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1596628999819,"user_tz":-120,"elapsed":1030,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"66b28d2d-c683-4933-bd42-9d39d47c33d5"},"source":["from typing import Dict\n","\n","import matplotlib.pyplot as plt\n","import nlp\n","import numpy as np\n","import pandas as pd\n","import torch\n","import transformers\n","from captum.attr import (IntegratedGradients, LayerIntegratedGradients,\n","                         configure_interpretable_embedding_layer,\n","                         remove_interpretable_embedding_layer)\n","from captum.attr import visualization as viz\n","from torch.utils.data import Dataset\n","from transformers import (ElectraForSequenceClassification,\n","                          ElectraTokenizerFast, EvalPrediction, InputFeatures,\n","                          Trainer, TrainingArguments, glue_compute_metrics)\n","\n","transformers.__version__"],"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.0.2'"]},"metadata":{"tags":[]},"execution_count":149}]},{"cell_type":"markdown","metadata":{"id":"wHa2VomPVf9r","colab_type":"text"},"source":["# Model\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"j3po0cgEvypP","colab_type":"text"},"source":["Sentiment analysis is a classification task that requires assigning a label to an entire sentence (sequence). We will use a PyTorch implementation of [`ElectraForSequenceClassification`](https://huggingface.co/transformers/model_doc/electra.html#electraforsequenceclassification) from the Hugging Face library. A matching tokenizer implemented in the [`ElectraTokenizerFast`](https://huggingface.co/transformers/model_doc/electra.html#electratokenizerfast) class will handle tokenization."]},{"cell_type":"code","metadata":{"id":"_TioBrt5VhIr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"ok","timestamp":1596629126472,"user_tz":-120,"elapsed":3309,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"1eca6e62-1e47-43aa-f8c2-c12401084f65"},"source":["model = ElectraForSequenceClassification.from_pretrained(\n","    \"google/electra-small-discriminator\", num_labels = 2)\n","\n","tokenizer = ElectraTokenizerFast.from_pretrained(\n","    \"google/electra-small-discriminator\", do_lower_case=True)                      "],"execution_count":151,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7SdUQg2ntJYj","colab_type":"text"},"source":["# Data\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"--54_ugqalQb","colab_type":"text"},"source":["\n","**Download**\n","\n","Let's now download the SST-2 dataset from the nlp library and take a brief look at it. It contains short movie reviews labelled for sentiment: 0 for negative and 1 for a positive review. The data is split into training, validation and test set. The labels for the test set are kept undisclosed."]},{"cell_type":"code","metadata":{"id":"SEn6pshAVkmw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"status":"ok","timestamp":1596629134835,"user_tz":-120,"elapsed":2814,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"233a31c7-a573-49c9-c9ea-89be9c61aac1"},"source":["# Load the SST2 dataset from the nlp library\n","dataset = nlp.load_dataset(\"glue\", \"sst2\")\n","\n","# Look at the labels\n","print(\"Training set labels: {}\".format(set(dataset[\"train\"][\"label\"])))\n","print(\"Validation set labels: {}\".format(set(dataset[\"validation\"][\"label\"])))\n","print(\"Test set labels: {}\".format(set(dataset[\"test\"][\"label\"])))\n","\n","# Explore the dataset\n","df = pd.DataFrame({\"senence\": dataset[\"train\"][\"sentence\"],\n","                   \"label\": dataset[\"train\"][\"label\"]})\n","pd.options.display.max_colwidth = 0\n","df.head()"],"execution_count":152,"outputs":[{"output_type":"stream","text":["Training set labels: {0, 1}\n","Validation set labels: {0, 1}\n","Test set labels: {-1}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>senence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hide new secretions from the parental units</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>contains no wit , only labored gags</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>that loves its characters and communicates something rather beautiful about human nature</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>remains utterly satisfied to remain the same throughout</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>on the worst revenge-of-the-nerds clichés the filmmakers could dredge up</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                     senence  label\n","0  hide new secretions from the parental units                                                0    \n","1  contains no wit , only labored gags                                                        0    \n","2  that loves its characters and communicates something rather beautiful about human nature   1    \n","3  remains utterly satisfied to remain the same throughout                                    0    \n","4  on the worst revenge-of-the-nerds clichés the filmmakers could dredge up                   0    "]},"metadata":{"tags":[]},"execution_count":152}]},{"cell_type":"markdown","metadata":{"id":"8E-1tg1jyAjJ","colab_type":"text"},"source":["**Create dataset**\n","\n","We will now create a custom [map-style PyTorch dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets) to serve model's key-value parameters in a seamless manner. \n","\n","The `TrainerDataset` class is derived from `torch.utils.data.Dataset`. The overridden `__getitem__` method yields a Python *Object* \n","for compatibility with [`DefaultDataCollator`](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py), in this example the `InputFeatures` class is used. \n","\n","Conversion to torch tensors and placing on cuda/cpu is handled by the `trainer` object used for fine-tuning."]},{"cell_type":"code","metadata":{"id":"Hg9gClv2VtGI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596629458073,"user_tz":-120,"elapsed":946,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["class TrainerDataset(Dataset):\n","    def __init__(self, inputs, targets, tokenizer):\n","        self.inputs = inputs\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","\n","        # Tokenize the input\n","        self.tokenized_inputs = tokenizer(inputs, padding=True)   \n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, idx):\n","        return InputFeatures(\n","            input_ids=self.tokenized_inputs['input_ids'][idx],\n","            token_type_ids=self.tokenized_inputs['token_type_ids'][idx],\n","            attention_mask=self.tokenized_inputs['attention_mask'][idx],\n","            label=self.targets[idx])         "],"execution_count":153,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Ncdro4DEcf4","colab_type":"text"},"source":["We need to create the training and validation datasets. As GLUE SST-2 dataset does not disclose labels for the test set, we will be using validation data for testing."]},{"cell_type":"code","metadata":{"id":"BIjHu-eMVu3e","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596629472311,"user_tz":-120,"elapsed":4796,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["train_dataset = TrainerDataset(dataset[\"train\"][\"sentence\"],\n","                               dataset[\"train\"][\"label\"], tokenizer)\n","eval_dataset = TrainerDataset(dataset[\"validation\"][\"sentence\"],\n","                              dataset[\"validation\"][\"label\"], tokenizer)"],"execution_count":154,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hki37gxJVxTX","colab_type":"text"},"source":["# Fine-tuning\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"CK6lfc6Hidmt","colab_type":"text"},"source":["Fine-tuning with a `Trainer` class instance requires setting training arguments and creating a `trainer` object. The model, as well as training and validation datasets, are passed to the trainer's constructor, along with training arguments. The `Trainer` class takes care of conversion to tensor format and placement on a cpu/gpu device."]},{"cell_type":"markdown","metadata":{"id":"lRZJsqMRwixQ","colab_type":"text"},"source":["## Set parameters"]},{"cell_type":"markdown","metadata":{"id":"y0F-0xBBwoSO","colab_type":"text"},"source":["Training parameters have been taken from the [Electra Github](https://github.com/google-research/electra/blob/master/configure_finetuning.py) repository or are default values. "]},{"cell_type":"code","metadata":{"id":"o2aR1A8LVzLH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596629507862,"user_tz":-120,"elapsed":893,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["# Set seed for reproducibility\n","np.random.seed(123)\n","torch.manual_seed(123)\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./models/model_electra\",\n","    num_train_epochs=3,\n","    overwrite_output_dir=True,\n","    do_train=True,\n","    do_eval=True,\n","    per_device_train_batch_size=32,\n","    evaluate_during_training=True,     \n","    dataloader_drop_last=True,  # Make sure all batches are of equal size\n",")\n","\n","\n","def compute_metrics(p: EvalPrediction) -> Dict:\n","    preds = np.argmax(p.predictions, axis=1)\n","    # The choice of a dataset (task_name) implies metric\n","    return glue_compute_metrics(\n","        task_name=\"sst-2\",\n","        preds=preds,\n","        labels=p.label_ids)\n","\n","\n","# Instantiate the Trainer class\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics)"],"execution_count":156,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AXTyBstWV1LM","colab_type":"text"},"source":["## Run fine-tuning"]},{"cell_type":"markdown","metadata":{"id":"Xr9UZ4PqiHo0","colab_type":"text"},"source":["Run the `train` method of the `trainer` object to fine-tune the model on the SST-2 dataset."]},{"cell_type":"code","metadata":{"id":"7lVhSg4IV23Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":598,"referenced_widgets":["f73e507aa2af47b3bc9cecd39821272f","cb5e9861778a41bca2fdf67b1b0aca9f","89c9e759616e4b1882c6d448bc874a47","ee6ad952e46c425cacafd0e9c5613358","a6c5133f196f46d5ad1655e18914d0fb","a9c2d45d97f64d92835a11ce052ecddb","224b778ebbbd4f6380bf710cc4094091","f135b4c180804c68a0d67672d43082b9","fd727c3a5360428ba44fbf6d564d8df4","1ae766edb0084cdbb03df357e8f66027","b75d7fd1e89e495a8459cdef9f027fed","6b2c10864ae344908749bf8b1ad5a42a","85bd960653d7498faca5a9e3bc74c2d3","425b95afa62f4638b3bed921805fd957","bcaf3f3d4c51403f8fe045a22cfd81b0","f67cc405c24840ea83f58383f7472cdf","c59a3412feed434cac44176654149978","fe97b77788224e3b8af9520c2ac33add","54d822a702ba464c9cc609b618d51e6d","c3731d79202245518597cda28ccf2c45","cbd92d1919bc41b0b68e34eaf47c091f","26867d3755a1442aa8feceb57e55fc27","a7287cb64bac4faab74683df6a099946","5e7f03852cca46aba8e2bd51bc96c7e9","46add80a07f648f285225de09e8b2a31","bdb5165a1e32420a9b86395ea9285fc3","8e5d9d6488ee462b9a4213c58847e2cd","49333a9665414763bd677232a64eecd4","75dbc827cef6468ea83a3f8e7a092293","e038c9bde67b4e1b95b39afbf5e21e71","c664b8fa3df74148bd73637c64e3741d","4320efbb0f9e47599d8c02bdd9539211","071ed4f183234e06b4c620916d6f971a","4251ab35d77740949abd90398d308ea6","86dbe43a671e42a5a29cfb509d658502","80bc136aae3848d48df1dcbe16a29c8b","a763ff9547144f97b6e9f9849db6e203","f79b10f21abe4e54909f1c420b872c79","8d194a640dce499990393bc17972c969","c9e3f61056c3409fbd28dbb592568f0e","80ecb10f47f1468081c6cbd5ef54e3dc","67521551b9ce43eaaebd943146572a6c","b8ecc557cd4f4d138e30cc054fb371fa","de7ef6bd81384184999d699f5b0977fe","a5c9c95c96854b218b83e2d785100e2e","8059bf371b3e4896ab437f2962c06c24","6e6c455e8fba44d3900bafa6844a0ec3","23af2d5302f74442b9242beeaedb4e6e","9476a88f5c394674b5a79aa90d481598","d89bdb4bd708498da09f02d11eee8620","c7ebec1f8c264a2a9c809ce341849513","a445bc39d3d9485381de6820357a753a","8fb34007c6be41dca6c7eedd9dd1d1a8","e469b003f5d548949472a9158a6b94e1","fdf7b79eab204aafacf9c0327df53d87","7abb30db3f4b479d97fa9be23d864057","4f0853b9c0af4d938cc2578b574f772d","7d47b456926e49389efc1df760552a12","4e9bcaab7300487190191dd657da8897","513ad2b8d82f4087ae4cd00acd13efb6","89630710c77e4b9f9bb0b548ebdd741b","cbe638e211d94de699c9484f8b860e30","a60d9126cb05441b852b1b5e83ddedda","06a3e7f0fa94452ea2a565effa6dd1d3","ae2835670a1a4eb6b27879234e85bab2","8ec925cd82cc417d99fe24912fb25d9b","63aa766714c4413a8a5172153d837f8a","4c3f89db878a43788725cd22a994efc8","631b0da0249f40e7b3be1947b4745715","9105d44d9a114e9bb5a6d2275a993530","cf2d35898b9a4945949c632c83b491ca","a45f564fded244cf9e4cc502b2f2eeb7","79e850e398b04d8a9891ebc7280a4942","91e449f7bde348a0b2a650ed86eee68d","d93a5d24dd3344cdb6f78960439fe2cb","8aa7da438be64279997d835154e13a2d","5fd9d67b3b2248148de23d91692ef665","eb351c57a6a74011854eafa5da7861eb","17ee77e84d9244329809f038eba816e7","798cf207c5d84d0fb4ce75b1c7b64755"]},"executionInfo":{"status":"ok","timestamp":1596630691308,"user_tz":-120,"elapsed":1158698,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"668216ff-45f9-4271-be74-fcf8e2ceb486"},"source":["trainer.train()"],"execution_count":157,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f73e507aa2af47b3bc9cecd39821272f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd727c3a5360428ba44fbf6d564d8df4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2104.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c59a3412feed434cac44176654149978","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46add80a07f648f285225de09e8b2a31","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"071ed4f183234e06b4c620916d6f971a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2104.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80ecb10f47f1468081c6cbd5ef54e3dc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9476a88f5c394674b5a79aa90d481598","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f0853b9c0af4d938cc2578b574f772d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2104.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae2835670a1a4eb6b27879234e85bab2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79e850e398b04d8a9891ebc7280a4942","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6312, training_loss=0.1881497751923481)"]},"metadata":{"tags":[]},"execution_count":157}]},{"cell_type":"markdown","metadata":{"id":"3-3V-0yv_r_L","colab_type":"text"},"source":["## Evaluate "]},{"cell_type":"markdown","metadata":{"id":"75MYAZtG1K-N","colab_type":"text"},"source":["The metric used for evaluation of the Stanford Sentiment Treebank (SST) data is *Accuracy*. The result is returned by the `Trainer` class object used for fine-tuning. "]},{"cell_type":"code","metadata":{"id":"kGz07rX7_lsJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["c714791ade614317a9bd7cb1e251735c","d399d03dc6504709a348ba34e7df9a4e","1b86f24b12bc4338a8f03775a90f8bec","00c3629ee3014c0d837f856f36356a1e","17408ba9c3584cafbfd1cf5038532841","0ae88ef38e5146018d500932aee7a195","e1d5227d28e94010b357ba2adea13187","9b3734aada6547c0850a77e8df9bd32f"]},"executionInfo":{"status":"ok","timestamp":1596630698637,"user_tz":-120,"elapsed":3133,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"63a2cde8-766d-4fe9-96d7-4957fa852bb0"},"source":["model_result = trainer.evaluate()\n","print(\"Accuracy: {}\".format(model_result[\"eval_acc\"]))"],"execution_count":158,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c714791ade614317a9bd7cb1e251735c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Accuracy: 0.9174311926605505\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M-V2TAFppOuz","colab_type":"text"},"source":["# Interpretability with Captum\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"wwaRQy2LrnQd","colab_type":"text"},"source":["The examples below use two attribution methods from the Captum library:\n","- **Integrated Gradients** - the method requires configuring interpretation hooks to perform attribution for all three embedding layers in one step, and\n","- **Layer Integrated Gradients**, computed separately with respect to each of the three layers:\n","    - `model.electra.embeddings.word_embeddings`,\n","    - `model.electra.embeddings.token_type_embeddings`,\n","    - `model.electra.embeddings.position_embeddings`.\n","\n","We will try to find out to what extent, according to these methods, each token has contributed to the model's prediction, or, more precisely, to its shift from the baseline output. \n","Each method requires setting a target class index: 0 for negative or 1 for a positive sentiment. Attribution is performed for each target class separately. Scores will be assigned with regard to the model's output for the selected class.\n","\n","The shape of attributions is the same as the shape of the `inputs` parameter of the `attribute` method."]},{"cell_type":"markdown","metadata":{"id":"ly7k0ryjp1C-","colab_type":"text"},"source":["Let's pick an example:"]},{"cell_type":"code","metadata":{"id":"c0uMvVUnzR4m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":93},"executionInfo":{"status":"ok","timestamp":1596630775260,"user_tz":-120,"elapsed":936,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"2105b13c-4b47-4ec8-84f7-f75c6c670d4e"},"source":["text = \"visually imaginative , thematically instructive and thoroughly \\\n","delightful , it takes us on a roller-coaster ride from innocence to experience \\\n","without even a hint of that typical kiddie-flick sentimentality . \"\n","true_label = 1\n","\n","[x for x in dataset[\"validation\"] if x[\"sentence\"] == text]"],"execution_count":159,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'idx': 857,\n","  'label': 1,\n","  'sentence': 'visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . '}]"]},"metadata":{"tags":[]},"execution_count":159}]},{"cell_type":"markdown","metadata":{"id":"SOQOBd8Hitie","colab_type":"text"},"source":["## Prepare input "]},{"cell_type":"markdown","metadata":{"id":"CHJo7nNBiPjV","colab_type":"text"},"source":["Set a cpu/gpu device according to availability. "]},{"cell_type":"code","metadata":{"id":"uw0e2qtajCrG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596630781169,"user_tz":-120,"elapsed":1291,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":160,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rlkMmJmiQg8","colab_type":"text"},"source":["**Helper functions**"]},{"cell_type":"markdown","metadata":{"id":"zxZg4TvKqPAH","colab_type":"text"},"source":["\n","The functions below **construct input tensors** for our sample and for a sequence of [PAD] tokens serving as a baseline. We also need to define a **forward function** running inference on the model. The function will be passed on to objects handling attribution. \n","\n","Computation with `IntegratedGradients` requires altering the model by **configuring additional layers**. For this purpose, the Captum library provides the `configure_interpretable_embedding_layer` and `remove_interpretable_embedding_layer` methods. Configuring an interpretable embedding layer modifies the model. A model with interpretable layers requires input of a different shape. "]},{"cell_type":"code","metadata":{"id":"J89L8HhDB1JM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596631067905,"user_tz":-120,"elapsed":1106,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["def predict_forward_func(input_ids, token_type_ids=None, \n","                         position_ids=None, attention_mask=None):\n","    \"\"\"Function passed to ig constructors\"\"\"\n","    return model(input_ids=input_ids, \n","                 token_type_ids=token_type_ids, \n","                 position_ids=position_ids, \n","                 attention_mask=attention_mask)[0]  \n","\n","\n","def prepare_input(text):\n","    \"\"\"Prepare ig attribution input: tokenize sample and baseline text.\"\"\"\n","    tokenized_text = tokenizer(text, return_tensors=\"pt\", \n","                               return_attention_mask=True)\n","    seq_len = tokenized_text[\"input_ids\"].shape[1]\n","    position_ids = torch.arange(seq_len, dtype=torch.long).unsqueeze(0)\n","\n","    # Construct the baseline (a reference sample).\n","    # A sequence of [PAD] tokens of length equal to that of the processed sample\n","    ref_text = tokenizer.pad_token * (seq_len - 2) # special tokens\n","    tokenized_ref_text = tokenizer(ref_text, return_tensors=\"pt\") \n","    ref_position_ids = torch.arange(seq_len, dtype=torch.long).unsqueeze(0)\n","\n","    return (tokenized_text[\"input_ids\"],\n","            tokenized_text[\"token_type_ids\"], \n","            position_ids,\n","            tokenized_ref_text[\"input_ids\"],\n","            tokenized_ref_text[\"token_type_ids\"], \n","            ref_position_ids,\n","            tokenized_text[\"attention_mask\"])   \n","\n","\n","def configure_interpretable_embeddings():\n","    \"\"\"Configure interpretable embedding layer\"\"\"\n","    interpretable_embedding1 = \\\n","    configure_interpretable_embedding_layer(\n","        model,\n","        'electra.embeddings.word_embeddings')\n","    interpretable_embedding2 = \\\n","    configure_interpretable_embedding_layer(\n","        model,\n","        'electra.embeddings.token_type_embeddings')\n","    interpretable_embedding3 = \\\n","    configure_interpretable_embedding_layer(\n","        model,\n","        'electra.embeddings.position_embeddings')\n","    return (interpretable_embedding1,\\\n","            interpretable_embedding2,\\\n","            interpretable_embedding3)\n","\n","\n","def remove_interpretable_embeddings(interpretable_embedding1, \n","                                    interpretable_embedding2, \n","                                    interpretable_embedding3):\n","    \"\"\"Remove interpretable layer to restore the original model structure\"\"\"\n","    if not \\\n","    type(model.get_input_embeddings()).__name__ == \"InterpretableEmbeddingBase\":\n","        return\n","    remove_interpretable_embedding_layer(model, interpretable_embedding1)\n","    remove_interpretable_embedding_layer(model, interpretable_embedding2)\n","    remove_interpretable_embedding_layer(model, interpretable_embedding3)    \n","\n","\n","def prepare_input_embed(input_ids, token_type_ids, position_ids,\n","                        ref_input_ids, ref_token_type_ids, ref_position_ids,\n","                        attention_mask):\n","    \"\"\"Construct input for the modified model\"\"\"\n","    input_ids_embed = interpretable_embedding1.indices_to_embeddings(input_ids)\n","    ref_input_ids_embed = interpretable_embedding1.indices_to_embeddings(\n","        ref_input_ids)\n","    token_type_ids_embed = interpretable_embedding2.indices_to_embeddings(\n","        token_type_ids)\n","    ref_token_type_ids_embed = interpretable_embedding2.indices_to_embeddings(\n","        ref_token_type_ids)\n","    position_ids_embed = interpretable_embedding3.indices_to_embeddings(\n","        position_ids)\n","    ref_position_ids_embed = interpretable_embedding3.indices_to_embeddings(\n","        ref_position_ids)\n","    \n","    return (input_ids_embed, token_type_ids_embed, position_ids_embed,\\\n","    ref_input_ids_embed, ref_token_type_ids_embed, ref_position_ids_embed, \\\n","    attention_mask)\n","\n","\n","def place_on_device(*tensors):\n","    tensors_device = []\n","    for t in tensors:\n","        tensors_device.append(t.to(device))\n","    return tuple(tensors_device)  "],"execution_count":165,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4BN3x0ISIazV","colab_type":"text"},"source":["## Integrated Gradients"]},{"cell_type":"markdown","metadata":{"id":"asVO1IpJyt8r","colab_type":"text"},"source":["To compute attributions with Integrated Gradients we will:\n","- instantiate the `IntegratedGradients` class passing the `predict_forward_func` function as parameter,\n","- configure interpretable embedding layer,\n","- prepare input tensors,\n","- compute attributions,\n","- remove interpratable embedding layer.\n","\n","Calling the `get_input_embeddings` method of the model helps to find out whether extra layers have been configured."]},{"cell_type":"markdown","metadata":{"id":"LMQKjnurz9qz","colab_type":"text"},"source":["### Compute attributions"]},{"cell_type":"code","metadata":{"id":"g8ZNDXGZIhW_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596631169021,"user_tz":-120,"elapsed":999,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["# Instantiate the IntegratedGradients class\n","ig = IntegratedGradients(predict_forward_func)"],"execution_count":166,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0ifAYT8Ij_T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1596631183590,"user_tz":-120,"elapsed":2113,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"83a0a9c3-c1c2-452f-979f-1688a9e38a6e"},"source":["# Configure interpretable embeddings layer \n","print(\"Oryginal model input embeddings:\\n {}\\n\".\n","      format(model.get_input_embeddings()))\n","if not type(model.get_input_embeddings()).__name__ == \"InterpretableEmbeddingBase\":\n","    interpretable_embedding1, interpretable_embedding2, interpretable_embedding3 =\\\n","    configure_interpretable_embeddings()\n","print(\"Input embeddings with interpretable layer:\\n {}\\n\".\n","      format(model.get_input_embeddings()))\n","\n","# Prepare input for the sample and for the baseline (reference)\n","input_data = prepare_input(text)\n","input_data = place_on_device(*input_data) \n","input_data_embed = prepare_input_embed(*input_data) \n","input_ids_embed, token_type_ids_embed, position_ids_embed = input_data_embed[0:3]\n","ref_input_ids_embed, ref_token_type_ids_embed, \\\n","ref_position_ids_embed = input_data_embed[3:6]\n","attention_mask = input_data_embed[-1]\n","\n","# Compute attributions for both target classes\n","# class 0 (negative)\n","attributions_0, approximation_error_0 = ig.attribute(\n","    inputs=(input_ids_embed, token_type_ids_embed, position_ids_embed),\n","    baselines=(ref_input_ids_embed, \n","               ref_token_type_ids_embed, \n","               ref_position_ids_embed),\n","               additional_forward_args=(attention_mask),\n","               target = 0, # Set target class here\n","               return_convergence_delta=True, \n","               n_steps=200)\n","# class 1 (positive)\n","attributions_1, approximation_error_1 = ig.attribute(\n","    inputs=(input_ids_embed, token_type_ids_embed, position_ids_embed),\n","    baselines=(ref_input_ids_embed, \n","               ref_token_type_ids_embed, \n","               ref_position_ids_embed),\n","               additional_forward_args=(attention_mask),\n","               target = 1, # Set target class here\n","               return_convergence_delta=True, \n","               n_steps=200)\n","\n","# Remove interpratable embeddings layer used by ig attribution\n","remove_interpretable_embeddings(interpretable_embedding1, \n","                                interpretable_embedding2, \n","                                interpretable_embedding3)\n","print(\"\\nInput embeddings with interpretable layer removed:\\n {}\\n\"\n",".format(model.get_input_embeddings()))\n","\n","print(\"\\nThe reference sample:\\n{}\".format(tokenizer.convert_ids_to_tokens(\n","    ref_input_ids.clone().detach().to('cpu').numpy().squeeze())))"],"execution_count":168,"outputs":[{"output_type":"stream","text":["Oryginal model input embeddings:\n"," Embedding(30522, 128, padding_idx=0)\n","\n","Input embeddings with interpretable layer:\n"," InterpretableEmbeddingBase(\n","  (embedding): Embedding(30522, 128, padding_idx=0)\n",")\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n","  \"In order to make embedding layers more interpretable they will \"\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Input embeddings with interpretable layer removed:\n"," Embedding(30522, 128, padding_idx=0)\n","\n","\n","The reference sample:\n","['[CLS]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"turkFMM8Ng6n","colab_type":"text"},"source":["### Completeness"]},{"cell_type":"markdown","metadata":{"id":"Kpltx2dbvNfa","colab_type":"text"},"source":["The Integrated Gradients method satisfies the completeness property. The sum of attributions should be equal, with certain accuracy, to the difference between the model's output for the sample and its output for the selected baseline (in this case a sequence of [PAD] tokens). Increase the `n_steps` parameter of the `ig.attribute` method to obtain better accuracy."]},{"cell_type":"code","metadata":{"id":"raXBOcBN2up6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"status":"ok","timestamp":1596631217620,"user_tz":-120,"elapsed":1029,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"367d36ce-cc79-4338-d414-ec99861f4799"},"source":["def check_completeness(attributions_0, attributions_1):\n","    input_ids, token_type_ids, position_ids, \\\n","    ref_input_ids, ref_token_type_ids, ref_position_ids, attention_mask = input_data\n","\n","    # Prediction for the sample\n","    scores = predict_forward_func(input_ids, token_type_ids,\n","                                position_ids, attention_mask) \n","\n","    # Prediction for the baseline\n","    ref_scores = predict_forward_func(ref_input_ids, ref_token_type_ids,\n","                                    ref_position_ids, attention_mask)\n","\n","    # How prediction for the sample differs from baseline prediction  \n","    diff_from_baseline = scores - ref_scores\n","    diff_from_baseline = diff_from_baseline.clone().detach().to('cpu').numpy()[0]\n","\n","    # Put on cpu\n","    if torch.is_tensor(attributions_0[0]):\n","        attributions_0 = [x.clone().detach().to('cpu').numpy() for x in attributions_0]\n","    if torch.is_tensor(attributions_1[0]):\n","        attributions_1 = [x.clone().detach().to('cpu').numpy() for x in attributions_1]\n","\n","    # Sum of attributions\n","    attributions_sum0 = [x.sum() for x in attributions_0]\n","    attributions_sum1 = [x.sum() for x in attributions_1]\n","    attributions_sum = [sum(attributions_sum0), sum(attributions_sum1)]\n","    diff = diff_from_baseline - attributions_sum\n","\n","    # Find out which layers contribute to the score \n","    print(\"Class 0: input tokens attr. sum: {}\".format(attributions_sum0[0]))\n","    print(\"Classs 0: token type attr. sum: {}\".format(attributions_0[1].sum()))\n","    print(\"Class 0: position ids attr. sum: {}\".format(attributions_0[2].sum()))\n","    print(\"Class 1: input tokens attr. sum: {}\".format(attributions_1[0].sum()))\n","    print(\"Classs 1: token type attr. sum: {}\".format(attributions_1[1].sum()))\n","    print(\"Class 1: position ids attr. sum: {}\".format(attributions_1[2].sum()))\n","\n","    # Compare sum of attributions and difference from the baseline prediction\n","    print(\"\\nPrediction for sample: {}\".format(scores))\n","    print(\"Prediction for baseline: {}\".format(ref_scores))\n","    print(\"Difference from baseline: {}\".format(diff_from_baseline))\n","    print(\"Sum of attributions: {}\".format(attributions_sum))\n","    print(\"\\nClass 0:\\n score: {}\\n reference score: {}\\\n","    \\n difference from ref.:{}\\n attributions: {}\\\n","    \\n difference from reference - attributions: {}\".\\\n","    format(scores[0][0], ref_scores[0][0], diff_from_baseline[0], \n","            attributions_sum[0], diff[0]))\n","    print(\"\\nClass 1:\\n score: {}\\n reference score: {}\\\n","    \\n difference from ref.:{}\\n attributions: {}\\\n","    \\n difference from reference - attributions: {}\".\\\n","    format(scores[0][1], ref_scores[0][1], diff_from_baseline[1], \n","            attributions_sum[1], diff[1]))\n","    \n","    return attributions_0, attributions_1\n","    \n","    \n","attributions_0, attributions_1 = check_completeness(attributions_0, \n","                                                    attributions_1)    "],"execution_count":170,"outputs":[{"output_type":"stream","text":["Class 0: input tokens attr. sum: -3.5737039708554974\n","Classs 0: token type attr. sum: 0.0\n","Class 0: position ids attr. sum: 0.0\n","Class 1: input tokens attr. sum: 3.526860935822965\n","Classs 1: token type attr. sum: 0.0\n","Class 1: position ids attr. sum: 0.0\n","\n","Prediction for sample: tensor([[-3.2152,  3.1105]], device='cuda:0', grad_fn=<AddmmBackward>)\n","Prediction for baseline: tensor([[ 0.3585, -0.4163]], device='cuda:0', grad_fn=<AddmmBackward>)\n","Difference from baseline: [-3.5737092  3.526866 ]\n","Sum of attributions: [-3.5737039708554974, 3.526860935822965]\n","\n","Class 0:\n"," score: -3.2151730060577393\n"," reference score: 0.3585362136363983    \n"," difference from ref.:-3.57370924949646\n"," attributions: -3.5737039708554974    \n"," difference from reference - attributions: -5.2786409625582564e-06\n","\n","Class 1:\n"," score: 3.1105339527130127\n"," reference score: -0.4163319170475006    \n"," difference from ref.:3.5268659591674805\n"," attributions: 3.526860935822965    \n"," difference from reference - attributions: 5.023344515464601e-06\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GGv8Z_rPWpxs","colab_type":"text"},"source":["## Layer Integrated Gradients"]},{"cell_type":"markdown","metadata":{"id":"-g85-8mizbf4","colab_type":"text"},"source":["With Layer Integrated Gradients, attributions are computed with respect to a certain layer. We'll run the algorithm for three [layers](https://github.com/huggingface/transformers/blob/d5b0a0e235cc6fccba4f9013cdb54cee01e90a91/src/transformers/modeling_electra.py#L131) separately: \n","- `model.electra.embeddings.word_embeddings`\n","- `model.electra.embeddings.token_type_embeddings`\n","- `model.electra.embeddings.position_embeddings`\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VtkHVIz80pmG","colab_type":"text"},"source":["### Compute attributions"]},{"cell_type":"markdown","metadata":{"id":"48x070y7El1n","colab_type":"text"},"source":["Assigning attributions with Layer Integrated Gradients requires:\n","- instantiating the `LayerIntegratedGradients` class and passing the `predict_forward_func` function along with a selected layer as parameters,\n","- calling the `attribute` function of the `LayerIntegratedGradients` instance to assign values to each token."]},{"cell_type":"code","metadata":{"id":"AhxxF_rIXDqr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1596631439987,"user_tz":-120,"elapsed":4235,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"3d6f673f-74c0-449c-826e-5b7cb9155332"},"source":["# Input for lig attributions (model with no special layers configured)\n","input_ids, token_type_ids, position_ids,\\\n","ref_input_ids, ref_token_type_ids, ref_position_ids, attention_mask = input_data\n","\n","# 1. Layer: model.electra.embeddings.word_embeddings\n","lig_word_we = LayerIntegratedGradients(\n","    predict_forward_func, \n","    model.electra.embeddings.word_embeddings)\n","lig = lig_word_we\n","\n","layer_attributions_we_0, _ = lig_word_we.attribute(\n","    inputs=input_ids, baselines=ref_input_ids,\n","    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n","    return_convergence_delta=True, target=0, n_steps=200)\n","\n","layer_attributions_we_1, _ = lig_word_we.attribute(\n","    inputs=input_ids, baselines=ref_input_ids,\n","    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n","    return_convergence_delta=True, target=1, n_steps=200)\n","\n","# 2. Layer: model.electra.embeddings.token_type_embeddings\n","lig_word_tte = LayerIntegratedGradients(\n","    predict_forward_func, \n","    model.electra.embeddings.token_type_embeddings)\n","\n","layer_attributions_tte_0, _ = lig_word_tte.attribute(\n","    inputs=input_ids, baselines=ref_input_ids,\n","    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n","    return_convergence_delta=True, target=0, n_steps=200)\n","\n","layer_attributions_tte_1, _ = lig_word_tte.attribute(\n","    inputs=input_ids, baselines=ref_input_ids,\n","    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n","    return_convergence_delta=True, target=1, n_steps=200)\n","\n","# 3. Layer: model.electra.embeddings.position_embeddings\n","lig_word_pe = LayerIntegratedGradients(\n","    predict_forward_func, \n","    model.electra.embeddings.position_embeddings)\n","\n","layer_attributions_pe_0, _ = lig_word_pe.attribute(\n","    inputs=input_ids, baselines=ref_input_ids,\n","    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n","    return_convergence_delta=True, target=0, n_steps=200)\n","\n","layer_attributions_pe_1, _ = lig_word_pe.attribute(\n","    inputs=input_ids, baselines=ref_input_ids,\n","    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n","    return_convergence_delta=True, target=1, n_steps=200)\n","\n","print(\"Shape of attributions:\")\n","print(layer_attributions_we_0.shape, layer_attributions_we_1.shape)\n","print(layer_attributions_tte_0.shape, layer_attributions_tte_1.shape)\n","print(layer_attributions_pe_0.shape, layer_attributions_pe_1.shape)"],"execution_count":178,"outputs":[{"output_type":"stream","text":["Shape of attributions:\n","torch.Size([1, 41, 128]) torch.Size([1, 41, 128])\n","torch.Size([1, 41, 128]) torch.Size([1, 41, 128])\n","torch.Size([1, 41, 128]) torch.Size([1, 41, 128])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ofIDYnUr994Y","colab_type":"text"},"source":["### Completeness"]},{"cell_type":"markdown","metadata":{"id":"L9uTWg6O-NuF","colab_type":"text"},"source":["Completeness for attributions found for each layer separately"]},{"cell_type":"code","metadata":{"id":"15G8-Qg69_0O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"status":"ok","timestamp":1596631457995,"user_tz":-120,"elapsed":979,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"9f013289-0ed2-4977-830b-fc47ee1491dd"},"source":["layer_attributions_0, layer_attributions_1 = check_completeness(\n","    (layer_attributions_we_0, layer_attributions_tte_0, layer_attributions_pe_0),\n","    (layer_attributions_we_1, layer_attributions_tte_1, layer_attributions_pe_1))"],"execution_count":182,"outputs":[{"output_type":"stream","text":["Class 0: input tokens attr. sum: -3.5737039708554974\n","Classs 0: token type attr. sum: 0.0\n","Class 0: position ids attr. sum: 0.0\n","Class 1: input tokens attr. sum: 3.526860935822965\n","Classs 1: token type attr. sum: 0.0\n","Class 1: position ids attr. sum: 0.0\n","\n","Prediction for sample: tensor([[-3.2152,  3.1105]], device='cuda:0', grad_fn=<AddmmBackward>)\n","Prediction for baseline: tensor([[ 0.3585, -0.4163]], device='cuda:0', grad_fn=<AddmmBackward>)\n","Difference from baseline: [-3.5737092  3.526866 ]\n","Sum of attributions: [-3.5737039708554974, 3.526860935822965]\n","\n","Class 0:\n"," score: -3.2151730060577393\n"," reference score: 0.3585362136363983    \n"," difference from ref.:-3.57370924949646\n"," attributions: -3.5737039708554974    \n"," difference from reference - attributions: -5.2786409625582564e-06\n","\n","Class 1:\n"," score: 3.1105339527130127\n"," reference score: -0.4163319170475006    \n"," difference from ref.:3.5268659591674805\n"," attributions: 3.526860935822965    \n"," difference from reference - attributions: 5.023344515464601e-06\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0HnTBKcFAjy5","colab_type":"text"},"source":["### Plot"]},{"cell_type":"markdown","metadata":{"id":"uASNIh0nA5H7","colab_type":"text"},"source":["**Compare with IG**"]},{"cell_type":"code","metadata":{"id":"W5iurfLHIpJ0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":454},"executionInfo":{"status":"ok","timestamp":1596631495788,"user_tz":-120,"elapsed":1785,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"482b20d8-2799-413d-f655-c6e75214e0ef"},"source":["# Attributions for input_ids computed wit IG and LIG\n","# word_embeddings: index 0\n","ig_1 = attributions_1[0].squeeze().sum(1)\n","lig_1 = layer_attributions_1[0].squeeze().sum(1)\n","\n","range_ig = [x + 0.5 for x in np.arange(len(ig_1))]\n","range_lig = [x + 0.5 for x in range_ig]\n"," \n","plt.bar(range_ig, ig_1, width=0.5, label='ig')\n","plt.bar(range_lig, lig_1, width=0.5, label='lig')\n","plt.xlabel('Token', fontweight='bold')\n","plt.xticks(list(range(len(lig_1))), tokens, rotation='vertical')\n","plt.legend()\n","plt.title(\"Attributions with IG and LIG for the positive target class.\")\n","plt.show()"],"execution_count":184,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"T-Q_DbqzBDL_","colab_type":"text"},"source":["**Plot for both target classes**\n","\n","Attributions assigned to tokens may take opposite values when computed with regard to class 0 and class 1.\n"]},{"cell_type":"code","metadata":{"id":"GMpxiV2fBD1W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":454},"executionInfo":{"status":"ok","timestamp":1596631512578,"user_tz":-120,"elapsed":1566,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"a522898e-e9a5-4993-a61d-7b6dc5f1bd1d"},"source":["# Attributions for word_embeddings: index 0\n","lig_0 = layer_attributions_0[0].squeeze().sum(1)\n","lig_1 = layer_attributions_1[0].squeeze().sum(1)\n","\n","tokens = tokenizer.convert_ids_to_tokens(tokenizer(text)[\"input_ids\"])\n","\n","plt.rcParams[\"figure.figsize\"] = [12, 6]\n","plt.bar(list(range(len(lig_0))), lig_0, color='r', alpha=0.5)\n","plt.bar(list(range(len(lig_1))), lig_1, color='g', alpha=0.5)\n","plt.xticks(list(range(len(lig_0))), tokens, rotation='vertical')\n","plt.legend(labels=[\"Target: negative\", \"Target: positive\"])\n","plt.xlabel('Token', fontweight='bold')\n","plt.title(\"Token attributions for positive and negative target class\")\n","plt.show()"],"execution_count":185,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"T9WIp8XJXrZc","colab_type":"text"},"source":["## Visualization"]},{"cell_type":"markdown","metadata":{"id":"tryuEZ0LbNNO","colab_type":"text"},"source":["### Helper functions"]},{"cell_type":"code","metadata":{"id":"5eNIcNg4-aFZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596631518743,"user_tz":-120,"elapsed":1160,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}}},"source":["def get_input_data(text):\n","    input_data = place_on_device(*prepare_input(text))\n","    input_data_embed = prepare_input_embed(*input_data)   \n","    return input_data, input_data_embed \n","\n","\n","def ig_attribute(class_index, input_data_embed):\n","    return ig.attribute(inputs=input_data_embed[0:3],\n","                        baselines=input_data_embed[3:6],\n","                        additional_forward_args=(input_data_embed[6]),\n","                        target = class_index,\n","                        return_convergence_delta=True,\n","                        n_steps=200)\n","    \n","\n","def lig_attribute(class_index, input_data):\n","    return lig.attribute(\n","        inputs=input_data[0], baselines=input_data[3],\n","        additional_forward_args=(input_data[1], input_data[2], input_data[6]),\n","        return_convergence_delta=True, target=class_index)\n","\n","\n","def summarize_attributions(attributions):\n","    attributions = attributions.sum(dim=-1).squeeze(0)\n","    attributions = attributions / torch.norm(attributions)\n","    return attributions\n","\n","\n","def compute_attributions_ig(input_data_embed):\n","    # Create interpretable layer\n","    if not type(\n","        model.get_input_embeddings()).__name__ == \"InterpretableEmbeddingBase\":    \n","        interpretable_embedding1, interpretable_embedding2,\\\n","        interpretable_embedding3 = configure_interpretable_embeddings()\n","    # Compute attributions for positive and nagative samples (class 1 and 0)\n","    attr_0, delta_0 = ig_attribute(0, input_data_embed)\n","    attr_1, delta_1 = ig_attribute(1, input_data_embed)\n","    # Remove interprateble layer used by ig attribution\n","    remove_interpretable_embeddings(interpretable_embedding1, \n","                                    interpretable_embedding2, \n","                                    interpretable_embedding3)\n","    # Return attributions for 'input_ids' (element 0) for 0 and 1 class indices\n","    return (attr_0[0], delta_0), (attr_1[0], delta_1)    \n","\n","\n","def compute_attributions_lig(input_data):  \n","    # Compute attributions for positive and nagative samples (class 1 and 0)\n","    return lig_attribute(0, input_data), lig_attribute(1, input_data)\n","\n","\n","def get_visualization_record(text, attributions, scores, true_label,\n","                             all_tokens, approximation_error):\n","    attributions_sum = summarize_attributions(attributions)\n","    return viz.VisualizationDataRecord(\n","        attributions_sum,\n","        torch.max(torch.softmax(scores[0], dim=0)),\n","        torch.argmax(scores),\n","        true_label,\n","        text,\n","        attributions_sum.sum(),\n","        all_tokens,\n","        approximation_error)\n","    \n","\n","def visualize_attributions(text, true_label, method):\n","    # Prepare input\n","    input_data = place_on_device(*prepare_input(text))\n","    input_data_embed = prepare_input_embed(*input_data)\n","    # Compute attributions\n","    attr_0, attr_1, delta_0, delta_1 = None, None, None, None\n","    if method == \"ig\":\n","        (attr_0, delta_0), (attr_1, delta_1) = \\\n","        compute_attributions_ig(input_data_embed)\n","    elif method == \"lig\":    \n","        (attr_0, delta_0), (attr_1, delta_1) = \\\n","        compute_attributions_lig(input_data)\n","    else:\n","        return \"method: ig or lig\"    \n","    # Run inference\n","    scores = predict_forward_func(*input_data[0:3], input_data[-1])\n","    # Prepare visualization \n","    indices = input_data[0][0].detach().tolist()\n","    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n","    data_vis_0 = get_visualization_record(text, attr_0, scores, \n","                                          true_label, all_tokens, delta_0)  \n","    data_vis_1 = get_visualization_record(text, attr_1, scores, \n","                                          true_label, all_tokens, delta_1) \n","    # Visualize\n","    print(\"\\nAttribution method: {},\".\n","          format(method), \"class index: 0 (negative)\")\n","    viz.visualize_text([data_vis_0])\n","    print(\"Attribution method: {},\".\n","          format(method), \"Class index: 1 (positive)\")\n","    viz.visualize_text([data_vis_1]) \n","    return attr_0, attr_1    "],"execution_count":186,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8m9IAb2Z-vn","colab_type":"text"},"source":["### Examples"]},{"cell_type":"markdown","metadata":{"id":"kGn3780AmD_Z","colab_type":"text"},"source":["Captum visualization library shows in green tokens that push the prediction towards the target class. Those driving the score towards the reference value are marked in red. As a result, words perceived as positive will appear in green if attribution is performed against class 1 (positive) but will be highlighted in red with an attribution targeting class 0 (negative).\n","\n","Because importance scores ar assigned to tokens, not words, some examples may show, that attribution is highly dependent on tokenization. Classification result may vary between runs.\n"]},{"cell_type":"markdown","metadata":{"id":"UHyNJIc39rUr","colab_type":"text"},"source":["Browse examples:"]},{"cell_type":"code","metadata":{"id":"ka-dgLIEgYPA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68,"referenced_widgets":["56590e5eb66f49faa8422f3f4cddf185","6afb1fd969014ce2a2e4604cec10f220","16d939947de14769bc993b5bb62840ed","b374e540049c44f7998d2298032384b5","fae44be6b2af4296992cf0a284683e5e","de35220dcb8044768bdaf74c48c785d3","9d8e3d612d15427188729f940d503d39","c0f46e709e74432581515986d9ce2c0e"]},"executionInfo":{"status":"ok","timestamp":1596631598159,"user_tz":-120,"elapsed":2829,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"f8567247-e634-4432-d482-7fe678583de7"},"source":["# Run predictions\n","eval_pred_result = trainer.predict(eval_dataset)\n","predictions = np.argmax(eval_pred_result.predictions, axis=1)\n","\n","# Find misclassifed samples\n","eval_samples = [tokenizer.decode(x.input_ids, skip_special_tokens=True) \\\n","                for x in eval_dataset]\n","eval_preds = list(zip(eval_pred_result.label_ids, predictions))\n","positive_pred_as_positive = [sample for sample, (real_label, pred_label) \\\n","                             in zip(eval_samples, eval_preds) \\\n","                             if real_label == pred_label and real_label == 1]  \n","negative_pred_as_negative = [sample for sample, (real_label, pred_label) \\\n","                             in zip(eval_samples, eval_preds) \\\n","                             if real_label == pred_label and real_label == 0]                               \n","negative_pred_as_positive = [sample for sample, (real_label, pred_label) \\\n","                             in zip(eval_samples, eval_preds) \\\n","                             if real_label != pred_label and real_label == 0]\n","positive_pred_as_negative = [sample for sample, (real_label, pred_label) \\\n","                             in zip(eval_samples, eval_preds) \\\n","                             if real_label != pred_label and real_label == 1]\n","\n","# Browse\n","# print('\\n'.join(positive_pred_as_positive))   \n","# print('\\n'.join(negative_pred_as_negative))    \n","# print('\\n'.join(negative_pred_as_positive))     \n","# print('\\n'.join(positive_pred_as_negative))                                          "],"execution_count":187,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56590e5eb66f49faa8422f3f4cddf185","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Prediction', max=109.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j6FcN8liZyda","colab_type":"text"},"source":["#### Positive"]},{"cell_type":"markdown","metadata":{"id":"IHHxBoJ7oMOM","colab_type":"text"},"source":["A correctly classified positive sample\n","\n","Use our example or pick your own by setting `text_vis` and `true_label_vis` variables."]},{"cell_type":"code","metadata":{"id":"AGrav0a8oecG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":862},"executionInfo":{"status":"ok","timestamp":1596631609291,"user_tz":-120,"elapsed":2480,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"00a38514-dc85-4d76-e4a6-d301dbb1bd79"},"source":["text_vis = text\n","true_label_vis = true_label\n","\n","ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n","lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"],"execution_count":189,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n","  \"In order to make embedding layers more interpretable they will \"\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Attribution method: ig, class index: 0 (negative)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . </b></text></td><td><text style=\"padding-right:2em\"><b>-4.02</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> imaginative                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thematic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ally                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ins                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##truct                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ive                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thoroughly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> delightful                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roller                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coaster                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ride                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innocence                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experience                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> without                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hint                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kidd                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flick                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sentimental                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ity                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Attribution method: ig, Class index: 1 (positive)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . </b></text></td><td><text style=\"padding-right:2em\"><b>3.99</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> imaginative                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thematic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ally                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ins                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##truct                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ive                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thoroughly                    </font></mark><mark style=\"background-color: hsl(120, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> delightful                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roller                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coaster                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ride                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innocence                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experience                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> without                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hint                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typical                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kidd                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flick                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sentimental                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ity                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Attribution method: lig, class index: 0 (negative)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . </b></text></td><td><text style=\"padding-right:2em\"><b>-4.02</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> imaginative                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thematic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ally                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ins                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##truct                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ive                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thoroughly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> delightful                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roller                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coaster                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ride                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innocence                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experience                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> without                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hint                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kidd                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flick                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sentimental                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ity                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Attribution method: lig, Class index: 1 (positive)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . </b></text></td><td><text style=\"padding-right:2em\"><b>3.99</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> imaginative                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thematic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ally                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ins                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##truct                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ive                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thoroughly                    </font></mark><mark style=\"background-color: hsl(120, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> delightful                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roller                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coaster                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ride                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innocence                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experience                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> without                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hint                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typical                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kidd                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flick                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sentimental                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ity                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"YJUKqnKJaBDo","colab_type":"text"},"source":["#### Negative"]},{"cell_type":"markdown","metadata":{"id":"VVf89iWsECJp","colab_type":"text"},"source":["A correctly classified negative sample\n","\n","Use our example or pick your own by setting `text_vis` and `true_label_vis` variables."]},{"cell_type":"code","metadata":{"id":"Ku4Jq-9zf-K8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":764},"executionInfo":{"status":"ok","timestamp":1596631627515,"user_tz":-120,"elapsed":2707,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"8b35967e-0e8c-4465-a01d-9308563b2133"},"source":["text_vis = 'the film makes a fatal mistake : it asks us to care about a young \\\n","man whose only apparent virtue is that he is not quite as unpleasant as some \\\n","of the people in his life.'\n","true_label_vis = 0\n","\n","ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n","lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"],"execution_count":190,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n","  \"In order to make embedding layers more interpretable they will \"\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Attribution method: ig, class index: 0 (negative)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>the film makes a fatal mistake : it asks us to care about a young man whose only apparent virtue is that he is not quite as unpleasant as some of the people in his life.</b></text></td><td><text style=\"padding-right:2em\"><b>1.79</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> makes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fatal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mistake                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asks                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> man                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> virtue                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quite                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unpleasant                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Attribution method: ig, Class index: 1 (positive)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>the film makes a fatal mistake : it asks us to care about a young man whose only apparent virtue is that he is not quite as unpleasant as some of the people in his life.</b></text></td><td><text style=\"padding-right:2em\"><b>-1.84</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> makes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fatal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mistake                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asks                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> man                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> virtue                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quite                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unpleasant                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Attribution method: lig, class index: 0 (negative)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>the film makes a fatal mistake : it asks us to care about a young man whose only apparent virtue is that he is not quite as unpleasant as some of the people in his life.</b></text></td><td><text style=\"padding-right:2em\"><b>1.80</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> makes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fatal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mistake                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asks                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> man                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> virtue                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quite                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unpleasant                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Attribution method: lig, Class index: 1 (positive)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>the film makes a fatal mistake : it asks us to care about a young man whose only apparent virtue is that he is not quite as unpleasant as some of the people in his life.</b></text></td><td><text style=\"padding-right:2em\"><b>-1.85</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> makes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fatal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mistake                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asks                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> man                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> virtue                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quite                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unpleasant                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"gzZhcUMKn3My","colab_type":"text"},"source":["#### Misclassified"]},{"cell_type":"markdown","metadata":{"id":"VCHm7T-ih-zZ","colab_type":"text"},"source":["Negative examples misclassified as positive"]},{"cell_type":"code","metadata":{"id":"_8sGOEfHNtQl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596631631907,"user_tz":-120,"elapsed":1125,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"b68d0ce4-764d-4878-cdfc-fbadf43192b8"},"source":["print('\\n\\n'.join(negative_pred_as_positive)) "],"execution_count":191,"outputs":[{"output_type":"stream","text":["the script kicks in, and mr. hartley's distended pace and foot - dragging rhythms follow.\n","\n","you won't like roger, but you will quickly recognize him.\n","\n","this riveting world war ii moral suspense story deals with the shadow side of american culture : racial prejudice in its ugly and diverse forms.\n","\n","sam mendes has become valedictorian at the school for soft landings and easy ways out.\n","\n","every nanosecond of the the new guy reminds you that you could be doing something else far more pleasurable.\n","\n","it seems to me the film is about the art of ripping people off without ever letting them consciously know you have done so\n","\n","the best that can be said about the work here of scottish director ritchie... is that he obviously doesn't have his heart in it.\n","\n","by getting myself wrapped up in the visuals and eccentricities of many of the characters, i found myself confused when it came time to get to the heart of the movie.\n","\n","determined to be fun, and bouncy, with energetic musicals, the humor didn't quite engage this adult.\n","\n","delivers the same old same old, tarted up with latin flava and turned out by hollywood playas.\n","\n","though perry and hurley make inspiring efforts to breathe life into the disjointed, haphazard script by jay scherick and david ronn, neither the actors nor director reginald hudlin can make it more than fitfully entertaining.\n","\n","it's hard to like a film about a guy who is utterly unlikeable, and shiner, starring michael caine as an aging british boxing promoter desperate for a taste of fame and fortune, is certainly that.\n","\n","k - 19 exploits our substantial collective fear of nuclear holocaust to generate cheap hollywood tension.\n","\n","the x potion gives the quickly named blossom, bubbles and buttercup supernatural powers that include extraordinary strength and laser - beam eyes, which unfortunately don't enable them to discern flimsy screenplays.\n","\n","i'll bet the video game is a lot more fun than the film.\n","\n","if director michael dowse only superficially understands his characters, he doesn't hold them in contempt.\n","\n","outer - space buffs might love this film, but others will find its pleasures intermittent.\n","\n","i don't mind having my heartstrings pulled, but don't treat me like a fool.\n","\n","with its dogged hollywood naturalism and the inexorable passage of its characters toward sainthood, windtalkers is nothing but a sticky - sweet soap.\n","\n","oh come on.\n","\n","a tv style murder mystery with a few big screen moments ( including one that seems to be made for a different film altogether ).\n","\n","a by - the - numbers patient / doctor pic that covers all the usual ground\n","\n","it showcases carvey's talent for voices, but not nearly enough and not without taxing every drop of one's patience to get to the good stuff.\n","\n","care deftly captures the wonder and menace of growing up, but he never really embraces the joy of fuhrman's destructive escapism or the grace - in - rebellion found by his characters.\n","\n","moretti's compelling anatomy of grief and the difficult process of adapting to loss.\n","\n","it has all the excitement of eating oatmeal.\n","\n","although huppert's intensity and focus has a raw exhilaration about it, the piano teacher is anything but fun.\n","\n","passable entertainment, but it's the kind of motion picture that won't make much of a splash when it's released, and will not be remembered long afterwards.\n","\n","every dance becomes about seduction, where backstabbing and betrayals are celebrated, and sex is currency.\n","\n","it takes a certain kind of horror movie to qualify as ` worse than expected,'but ghost ship somehow manages to do exactly that.\n","\n","vera's technical prowess ends up selling his film short ; he smoothes over hard truths even as he uncovers them.\n","\n","like you couldn't smell this turkey rotting from miles away.\n","\n","davis... is so enamored of her own creation that she can't see how insufferable the character is.\n","\n","the so - inept - it's - surreal dubbing ( featuring the voices of glenn close, regis philbin and breckin meyer ) brings back memories of cheesy old godzilla flicks.\n","\n","the longer the movie goes, the worse it gets, but it's actually pretty good in the first few minutes.\n","\n","sit through this one, and you won't need a magic watch to stop time ; your dvd player will do it for you.\n","\n","the man from elysian fields is a cold, bliss - less work that groans along thinking itself some important comment on how life throws us some beguiling curves.\n","\n","american chai encourages rueful laughter at stereotypes only an indian - american would recognize.\n","\n","very special effects, brilliantly bold colors and heightened reality can't hide the giant achilles'heel in ` ` stuart little 2 ` ` : there's just no story, folks.\n","\n","it's somewhat clumsy and too lethargically paced - - but its story about a mysterious creature with psychic abilities offers a solid build - up, a terrific climax, and some nice chills along the way.\n","\n","irwin is a man with enough charisma and audacity to carry a dozen films, but this particular result is ultimately held back from being something greater.\n","\n","i can take infantile humor... but this is the sort of infantile that makes you wonder about changing the director and writer's diapers.\n","\n","the movie, directed by mick jackson, leaves no cliche unturned, from the predictable plot to the characters straight out of central casting.\n","\n","an absurdist comedy about alienation, separation and loss.\n","\n","it's inoffensive, cheerful, built to inspire the young people, set to an unending soundtrack of beach party pop numbers and aside from its remarkable camerawork and awesome scenery, it's about as exciting as a sunburn.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WkAmTeq6u3oI","colab_type":"text"},"source":["Pick an example"]},{"cell_type":"code","metadata":{"id":"W9GoAAQROGDq","colab_type":"code","colab":{}},"source":["#text_vis = \"<example>\"\n","#true_label_vis = 0\n","\n","#ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n","#lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eTNNTfVdiEXk","colab_type":"text"},"source":["Positive examples misclassified as negative"]},{"cell_type":"code","metadata":{"id":"q9f9G-gdN1_8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596631638060,"user_tz":-120,"elapsed":852,"user":{"displayName":"Eliza Szczechla","photoUrl":"","userId":"15984572164832791190"}},"outputId":"370c2720-73ac-4a56-85d9-d769c3c738a6"},"source":["print('\\n\\n'.join(positive_pred_as_negative)) "],"execution_count":192,"outputs":[{"output_type":"stream","text":["one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others.\n","\n","if steven soderbergh's ` solaris'is a failure it is a glorious failure.\n","\n","turns potentially forgettable formula into something strangely diverting.\n","\n","the film tunes into a grief that could lead a man across centuries.\n","\n","a full world has been presented onscreen, not some series of carefully structured plot points building to a pat resolution.\n","\n","a coda in every sense, the pinochet case splits time between a minute - by - minute account of the british court's extradition chess game and the regime's talking - head survivors.\n","\n","as unseemly as its title suggests.\n","\n","while there's something intrinsically funny about sir anthony hopkins saying ` get in the car, bitch,'this jerry bruckheimer production has little else to offer\n","\n","you'll gasp appalled and laugh outraged and possibly, watching the spectacle of a promising young lad treading desperately in a nasty sea, shed an errant tear.\n","\n","( d ) oesn't bother being as cloying or preachy as equivalent evangelical christian movies - - maybe the filmmakers know that the likely audience will already be among the faithful.\n","\n","we haven't seen such hilarity since say it isn't so!\n","\n","something akin to a japanese alice through the looking glass, except that it seems to take itself far more seriously.\n","\n","intriguing documentary which is emotionally diluted by focusing on the story's least interesting subject.\n","\n","light years / several warp speeds / levels and levels of dilithium crystals better than the pitiful insurrection.\n","\n","harrison's flowers puts its heart in the right place, but its brains are in no particular place at all.\n","\n","on the heels of the ring comes a similarly morose and humorless horror movie that, although flawed, is to be commended for its straight - ahead approach to creepiness.\n","\n","another one of those estrogen overdose movies like ` ` divine secrets of the ya ya sisterhood,'' except that the writing, acting and character development are a lot better.\n","\n","this flick is about as cool and crowd - pleasing as a documentary can get.\n","\n","still, as a visual treat, the film is almost unsurpassed.\n","\n","the jabs it employs are short, carefully placed and dead - center.\n","\n","drops you into a dizzying, volatile, pressure - cooker of a situation that quickly snowballs out of control, while focusing on the what much more than the why.\n","\n","no screen fantasy - adventure in recent memory has the showmanship of clones'last 45 minutes.\n","\n","not since tom cruise in risky business has an actor made such a strong impression in his underwear.\n","\n","... routine, harmless diversion and little else.\n","\n","but it still jingles in the pocket.\n","\n","writer / director joe carnahan's grimy crime drama is a manual of precinct cliches, but it moves fast enough to cover its clunky dialogue and lapses in logic.\n","\n","the structure the film takes may find matt damon and ben affleck once again looking for residuals as this officially completes a good will hunting trilogy that was never planned.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NiLOTdTGu2Kf","colab_type":"text"},"source":["Pick an example"]},{"cell_type":"code","metadata":{"id":"IyKdJ2sEV0OE","colab_type":"code","colab":{}},"source":["#text_vis = \"<example>\"\n","#true_label_vis = 1\n","\n","#ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n","#lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D23Ejoku1P4b","colab_type":"text"},"source":["# References\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"u6GWu4mq1URt","colab_type":"text"},"source":["https://captum.ai/tutorials/Bert_SQUAD_Interpret\n","\n","https://captum.ai/docs/algorithms\n","\n","https://captum.ai/api/integrated_gradients.html\n","\n","https://github.com/google-research/electra/\n","\n","https://github.com/google-research/electra/blob/master/configure_finetuning.py\n","\n","https://github.com/huggingface/nlp/blob/master/notebooks/Overview.ipynb\n","\n","https://huggingface.co/transformers/main_classes/trainer.html"]}]}